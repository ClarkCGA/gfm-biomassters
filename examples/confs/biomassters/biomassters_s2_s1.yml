# lightning.pytorch==2.1.1

# For pritvhi600: select_indices = [7, 15, 23, 31], backbone_patch_size = 14
# For prithvi300: select_indices = [5, 11, 17, 23], backbone_patch_size = 16

seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: bf16-mixed
  logger:
    class_path: TensorBoardLogger
    init_args:
      save_dir: /output
      name: prithvi300_s1_s2_test
  callbacks:
  - class_path: RichProgressBar
  - class_path: LearningRateMonitor
    init_args:
      logging_interval: epoch
  - class_path: ModelCheckpoint
    init_args:
      filename: best-{epoch:02d}-{val_RMSE:.4f}
      monitor: val/RMSE
      save_top_k: 1
      mode: min
  - class_path: lightning.pytorch.callbacks.EarlyStopping
    init_args:
      monitor: val/RMSE
      patience: 10
      mode: min
  max_epochs: 50
  check_val_every_n_epoch: 1
  log_every_n_steps: 10
  enable_checkpointing: true

data:
  class_path: BioMasstersNonGeoDataModule
  init_args:
    data_root: '/data'
    batch_size: 1
    num_workers: 8
    bands:
      S1:
        - VV_Asc
        - VH_Asc
        - VV_Desc
        - VH_Desc
        - RVI_Asc
        - RVI_Desc
      S2:
        - BLUE
        - GREEN
        - RED
        # - RED_EDGE_1
        # - RED_EDGE_2
        # - RED_EDGE_3
        - NIR_BROAD
        # - NIR_NARROW
        - SWIR_1
        - SWIR_2
        # - CLOUD_PROBABILITY
    train_transform:
      - class_path: FlattenTemporalIntoChannels
      - class_path: albumentations.RandomCrop
        init_args:
          height: 224
          width: 224
      - class_path: albumentations.D4
      - class_path: ToTensorV2
      - class_path: UnflattenTemporalFromChannels
        init_args:
          n_timesteps: 4
    val_transform:
      - class_path: FlattenTemporalIntoChannels
      - class_path: albumentations.CenterCrop
        init_args:
          height: 224
          width: 224
      - class_path: ToTensorV2
      - class_path: UnflattenTemporalFromChannels
        init_args:
          n_timesteps: 4
    predict_transform: 
      - class_path: FlattenTemporalIntoChannels
      - class_path: albumentations.CenterCrop
        init_args:
          height: 224
          width: 224
      - class_path: ToTensorV2
      - class_path: UnflattenTemporalFromChannels
        init_args:
          n_timesteps: 4
    drop_last: true
    metadata_filename: "biomassters_chip_tracker.csv"
    sensors:
      - S2
      - S1
    as_time_series: true
    subset: 1.0
    use_four_frames: true
    concat_bands: true

model:
  class_path: terratorch.tasks.PixelwiseRegressionTask
  init_args:
    model_factory: EncoderDecoderFactory
    model_args:
      backbone: prithvi_eo_v2_300
      backbone_padding: reflect
      backbone_patch_size: 16
      backbone_num_frames: 4
      backbone_bands:
        - VV_Asc
        - VH_Asc
        - VV_Desc
        - VH_Desc
        - RVI_Asc
        - RVI_Desc
        - BLUE
        - GREEN
        - RED
        # - RED_EDGE_1
        # - RED_EDGE_2
        # - RED_EDGE_3
        - NIR_BROAD
        # - NIR_NARROW
        - SWIR_1
        - SWIR_2
        # - CLOUD_PROBABILITY
      rescale: true
      decoder: IdentityDecoder
      head_dropout: 0.1
      head_final_act: torch.nn.ReLU
      head_channel_list:
      - 128
      - 64
      necks:
      - name: SelectIndices
        indices:
          # - 2
          # - 5
          # - 8
          # - 11
          - 5
          - 11
          - 17
          - 23
        # - 7
        # - 15
        # - 23
        # - 31
      - name: ReshapeTokensToImage
        effective_time_dim: 4
      # peft_config:
      #   method: LORA
      #   replace_qkv: qkv
      #   peft_config_kwargs:
      #     target_modules:
      #     - qkv.q_linear
      #     - qkv.v_linear
      #     - mlp.fc1
      #     - mlp.fc2
      #     r: 8
      #     lora_alpha: 32
      #     lora_dropout: 0.1
    loss: rmse
    plot_on_val: True

optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 6.e-5
    weight_decay: 0.05
lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    monitor: val/loss

