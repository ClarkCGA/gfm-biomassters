# lightning.pytorch==2.1.1
seed_everything: 0
trainer:
  accelerator: gpu
  strategy: ddp
  devices: [0,1]
  #num_nodes: 2
  # precision: 16-mixed
  logger:
    #class_path: TensorBoardLogger
    class_path: lightning.pytorch.loggers.csv_logs.CSVLogger
    init_args:
      save_dir: <your_path_here>/torchgeo_uhi
      name: swin_bs_16_gpu_yaml
  callbacks:
    - class_path: RichProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: EarlyStopping
      init_args:
        monitor: val/loss
        patience: 200
  max_epochs: 200
  check_val_every_n_epoch: 1
  log_every_n_steps: 20
  enable_checkpointing: true
  default_root_dir: <your_path_here>/torchgeo_uhi
data:
  class_path: GenericNonGeoPixelwiseRegressionDataModule
  init_args:
    batch_size: 16
    num_workers: 8
    train_transform:
      - class_path: albumentations.HorizontalFlip
        init_args:
          p: 0.5
      - class_path: albumentations.Rotate
        init_args:
          limit: 30
          border_mode: 0 # cv2.BORDER_CONSTANT
          value: 0
          mask_value: 1
          p: 0.5
      - class_path: ToTensorV2
    dataset_bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
      - 7
      - 8
      - 9
    output_bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - 7
    rgb_indices:
      - 2
      - 1
      - 0
    train_data_root: /dccstor/sarl_data/urbanclimate/lst/lst_data_jhb/date_split/train/stacked_inputs
    train_label_data_root: /dccstor/sarl_data/urbanclimate/lst/lst_data_jhb/date_split/train/target
    val_data_root: /dccstor/sarl_data/urbanclimate/lst/lst_data_jhb/date_split/val/stacked_inputs
    val_label_data_root: /dccstor/sarl_data/urbanclimate/lst/lst_data_jhb/date_split/val/target
    test_data_root: /dccstor/sarl_data/urbanclimate/lst/lst_data_jhb/date_split/test/stacked_inputs
    test_label_data_root: /dccstor/sarl_data/urbanclimate/lst/lst_data_jhb/date_split/test/target
    #img_grep: "_inputs.tif"
    #label_grep: "*_lst.tif"

    means:
      - 8.39617655e+03
      - 8.18745135e+03 
      - 8.48797080e+03 
      - 1.16978433e+04
      - 1.21932271e+04 
      - 2.36724247e+01
    stds:
      - 1524.39632461 
      - 1584.9435815 
      - 1899.76735508 
      - 3618.81466613
      - 3724.80926965 
      - 5.07631916

model:
  class_path: PixelwiseRegressionTask
  init_args:
    model_args:
      decoder: UperNetDecoder
      pretrained: true
      backbone: prithvi_swin_90_us
      img_size: 512
      #backbone_adaptive_inference_size: True
      #backbone_window_size: 8
      backbone_drop_path_rate: 0.3
      # backbone_window_size: 8
      decoder_channels: 128
      in_channels: 6
      bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - 7
      num_frames: 1
      head_dropout: 0.5
      head_final_act: torch.nn.GELU
    loss: rmse
#    aux_heads:
#      - name: aux_head
#        decoder: FCNDecoder
#        decoder_args:
#            decoder_out_index: 2
#            head_dropout: 0.5
#           head_channel_list:
#            - 64
#          head_final_act: torch.nn.ReLU
#    aux_loss:
#      aux_head: 0.4
    ignore_index: -9999
    freeze_backbone: false
    freeze_decoder: false
    model_factory: PrithviModelFactory
    # uncomment this block for tiled inference
    # tiled_inference_parameters:
    #   h_crop: 224
    #   h_stride: 192
    #   w_crop: 224
    #   w_stride: 192
    #   average_patches: true
    tiled_inference_parameters:
       h_crop: 512
       h_stride: 512
       w_crop: 512
       w_stride: 512
       average_patches: true
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 0.001
    weight_decay: 0.05
lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    monitor: val/loss
# no way to pass interval: step except without config
# lr_scheduler:
#   class_path: OneCycleLR
#   init_args:
#     max_lr: 0.0005
#     epochs: 120
#     steps_per_epoch: 375 # 6008 / batch_size
#     pct_start: 0.025
#     # interval: step
#     div_factor: 10
#     final_div_factor: 5e4
#     # monitor: val/loss
