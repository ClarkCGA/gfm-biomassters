# lightning.pytorch==2.2.0.post0
seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16-mixed
  logger: true
  callbacks:
  - class_path: lightning.pytorch.callbacks.RichProgressBar
    init_args:
      refresh_rate: 1
      leave: false
      theme:
        description: white
        progress_bar: '#6206E0'
        progress_bar_finished: '#6206E0'
        progress_bar_pulse: '#6206E0'
        batch_progress: white
        time: grey54
        processing_speed: grey70
        metrics: white
        metrics_text_delimiter: ' '
        metrics_format: .3f
  - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    init_args:
      logging_interval: epoch
      log_momentum: false
      log_weight_decay: false
  fast_dev_run: false
  max_epochs: 200
  max_steps: -1
  overfit_batches: 0.0
  check_val_every_n_epoch: 1
  log_every_n_steps: 50
  enable_checkpointing: true
  accumulate_grad_batches: 1
  inference_mode: true
  use_distributed_sampler: true
  detect_anomaly: false
  barebones: false
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: <your_path_here>
out_dtype: int16
ModelCheckpoint:
  filename: '{epoch}'
  monitor: val/loss
  verbose: false
  save_top_k: 1
  mode: min
  save_weights_only: false
  auto_insert_metric_name: true
  enable_version_counter: true
StateDictModelCheckpoint:
  filename: '{epoch}_state_dict'
  monitor: val/loss
  verbose: false
  save_top_k: 1
  mode: min
  save_weights_only: true
  auto_insert_metric_name: true
  enable_version_counter: true
data:
  class_path: terratorch.datamodules.GenericNonGeoSegmentationDataModule
  init_args:
    batch_size: 16
    num_workers: 8
    train_data_root: /home/jalmeida/Datasets/senfloods/v1.1/data/flood_events/HandLabeled/S2Hand
    val_data_root: /home/jalmeida/Datasets/senfloods/v1.1/data/flood_events/HandLabeled/S2Hand
    test_data_root: /home/jalmeida/Datasets/senfloods/v1.1/data/flood_events/HandLabeled/S2Hand
    img_grep: '*_S2Hand.tif'
    label_grep: '*_LabelHand.tif'
    means:
    - 0.107582
    - 0.13471393
    - 0.12520133
    - 0.3236181
    - 0.2341743
    - 0.15878009
    stds:
    - 0.07145836
    - 0.06783548
    - 0.07323416
    - 0.09489725
    - 0.07938496
    - 0.07089546
    num_classes: 2
    train_label_data_root: /home/jalmeida/Datasets/senfloods/v1.1/data/flood_events/HandLabeled/LabelHand
    val_label_data_root: /home/jalmeida/Datasets/senfloods/v1.1/data/flood_events/HandLabeled/LabelHand
    test_label_data_root: /home/jalmeida/Datasets/senfloods/v1.1/data/flood_events/HandLabeled/LabelHand
    train_split: /home/jalmeida/Datasets/senfloods/v1.1/splits/flood_handlabeled/flood_train_data.txt
    val_split: /home/jalmeida/Datasets/senfloods/v1.1/splits/flood_handlabeled/flood_valid_data.txt
    test_split: /home/jalmeida/Datasets/senfloods/v1.1/splits/flood_handlabeled/flood_test_data.txt
    ignore_split_file_extensions: true
    allow_substring_split_file: true
    dataset_bands:
    - RED
    - GREEN
    - BLUE
    - NIR_NARROW
    - SWIR_1
    - SWIR_2
    output_bands:
    - BLUE
    - GREEN
    - RED
    - NIR_NARROW
    - SWIR_1
    - SWIR_2
    constant_scale: 0.0001
    rgb_indices:
    - 2
    - 1
    - 0
    expand_temporal_dimension: false
    reduce_zero_label: false
    drop_last: true
model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
    model_args:
      decoder: FCNDecoder
      pretrained: true
      backbone: prithvi_vit_100
      backbone_pretrain_img_size: 512
      backbone_embed_dim: 768
      backbone_num_heads: 12
      backbone_decoder_depth: 8
      backbone_decoder_num_heads: 16
      backbone_decoder_embed_dim: 512
      backbone_mlp_ratio: 4
      backbone_patch_size: 16
      backbone_in_chans: 6
      backbone_num_frames: 1
      backbone_checkpoint_path: /home/jalmeida/checkpoints/epoch-725-loss-0.0365.pt
      decoder_channels: 256
      in_channels: 6
      bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
      num_frames: 1
      num_classes: 2
      head_dropout: 0.1
      decoder_num_convs: 4
      head_channel_list:
      - 256
    model_factory: PrithviModelFactory
    loss: ce
    aux_heads:
    - name: aux_head
      decoder: FCNDecoder
      decoder_args:
        decoder_channels: 256
        decoder_in_index: -1
        decoder_num_convs: 2
        head_dropout: 0.1
    aux_loss:
      aux_head: 1.0
    ignore_index: -1
    lr: 0.001
    optimizer: Adam
    freeze_backbone: false
    freeze_decoder: false
    plot_on_val: 10
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 6.0e-05
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    weight_decay: 0.05
    amsgrad: false
    maximize: false
    capturable: false
    differentiable: false
lr_scheduler:
  class_path: lightning.pytorch.cli.ReduceLROnPlateau
  init_args:
    monitor: val/loss
    mode: min
    factor: 0.1
    patience: 10
    threshold: 0.0001
    threshold_mode: rel
    cooldown: 0
    min_lr: 0.0
    eps: 1.0e-08
    verbose: false
