# lightning.pytorch==2.1.1
seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16-mixed
  logger:
    class_path: TensorBoardLogger
    init_args:
      save_dir: output
      name: sen1floods11_MM
  callbacks:
    - class_path: RichProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: EarlyStopping
      init_args:
        monitor: val/loss
        patience: 40

  max_epochs: 2
  check_val_every_n_epoch: 1
  log_every_n_steps: 50
  enable_checkpointing: true
  default_root_dir: output/sen1floods11_MM/

data:
  class_path: GenericMultiModalDataModule
  init_args:
    task: 'segmentation'
    batch_size: 4
    num_workers: 0
    modalities:
      - S2L2A
      - S1
      - LULC
    S2L2A_dataset_bands:
      - COASTAL_AEROSOL
      - BLUE
      - GREEN
      - RED
      - RED_EDGE_1
      - RED_EDGE_2
      - RED_EDGE_3
      - NIR_BROAD
      - NIR_NARROW
      - CIRRUS
      - SWIR_1
      - SWIR_2
    S2L2A_output_bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    S1_dataset_bands:
      - vv
      - vh
    S1_output_bands:
      - vv
      - vh
    LULC_dataset_bands:
      - lulc
    LULC_output_bands:
      - lulc
    rgb_modality: S2L2A # If not provided, uses first modality
    rgb_indices:
      - 0
      - 1
      - 2

    train_S2L2A_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/S2L2AHand
    train_S1_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/S1Hand
    train_LULC_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/LULCHand
    train_label_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/LabelHand
    val_S2L2A_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/S2L2AHand
    val_S1_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/S1Hand
    val_LULC_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/LULCHand
    val_label_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/LabelHand
    test_S2L2A_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/S2L2AHand
    test_S1_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/S1Hand
    test_LULC_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/LULCHand
    test_label_data_root: data/sen1floods11/data/data/flood_events/HandLabeled/LabelHand

    train_split: data/sen1floods11/splits/splits/flood_handlabeled/dev_train.txt
    val_split: data/sen1floods11/splits/splits/flood_handlabeled/dev_valid.txt
    test_split: data/sen1floods11/splits/splits/flood_handlabeled/dev_test.txt

    S2L2A_grep: "*_S2L2AHand.tif"
    S1_grep: "*_S1Hand.tif"
    LULC_grep: "*_LULCHand.npy"
    label_grep: "*_LabelHand.tif"
    no_data_replace: 0
    no_label_replace: -1

    S2L2A_constant_scale: 1.
    S1_constant_scale: 1.
    LULC_constant_scale: 1.

    S2L2A_means:
      - 0.1412956
      - 0.13795798
      - 0.12353792
      - 0.30902815
      - 0.2044958
      - 0.11912015
    S2L2A_stds:
      - 0.07406382
      - 0.07370365
      - 0.08692279
      - 0.11798815
      - 0.09772074
      - 0.07659938
    S1_means:
      - -20
      - -20
    S1_stds:
      - 10
      - 10
    LULC_means:
      - 0
    LULC_stds:
      - 1

    num_classes: 2

#    train_transform:
#      - class_path: albumentations.CenterCrop  # TODO: How to handle transforms with multiple modalities?
#        init_args:
#          height: 224
#          width: 224
#      - class_path: albumentations.HorizontalFlip
#        init_args:
#          p: 0.5
#      - class_path: ToTensorV2


model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
    model_factory: PrithviModelFactory
    model_args:
      decoder: FCNDecoder
      pretrained: true
      backbone: prithvi_vit_100
      decoder_channels: 256
      in_channels: 6
      bands:
        - BLUE
        - GREEN
        - RED
        - NIR_NARROW
        - SWIR_1
        - SWIR_2
      num_frames: 1
      num_classes: 2
      head_dropout: 0.1
      decoder_num_convs: 4
      head_channel_list:
        - 256
    loss: ce
    ignore_index: -1
    class_weights:
      - 0.3
      - 0.7
    freeze_backbone: false
    freeze_decoder: false


optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 6.e-5
    weight_decay: 0.05
lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    monitor: val/loss

